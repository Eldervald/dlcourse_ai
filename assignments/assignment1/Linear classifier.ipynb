{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
    "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "\n",
    "В этом задании вы:\n",
    "- потренируетесь считать градиенты различных многомерных функций\n",
    "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "- реализуете процесс тренировки линейного классификатора\n",
    "- подберете параметры тренировки на практике\n",
    "\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, первым делом загружаем данные\n",
    "\n",
    "Мы будем использовать все тот же SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float64) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float64) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Играемся с градиентами!\n",
    "\n",
    "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
    "\n",
    "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
    "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
    "```\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Computes function and analytic gradient at x\n",
    "    \n",
    "    x: np array of float, input to the function\n",
    "    \n",
    "    Returns:\n",
    "    value: float, value of the function \n",
    "    grad: np array of float, same shape as x\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    return value, grad\n",
    "```\n",
    "\n",
    "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
    "\n",
    "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
    "\n",
    "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
    "\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d)\n",
    "\n",
    "Все функции приведенные в следующей клетке должны проходить gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement check_gradient function in gradient_check.py\n",
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Начинаем писать свои функции, считающие аналитический градиент\n",
    "\n",
    "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней учавствует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
    "\n",
    "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
    "```\n",
    "predictions -= np.max(predictions)\n",
    "```\n",
    "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement softmax and cross-entropy for single sample\n",
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
    "В общем виде cross-entropy определена следующим образом:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
    "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
    "\n",
    "Это позволяет реализовать функцию проще!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.006760443547122"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
    "\n",
    "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
    "\n",
    "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
    "\n",
    "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
    "\n",
    "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
    "\n",
    "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO Extend combined function so it can receive a 2d array with batch of samples\n",
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float64)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(np.int32)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(np.float64)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size)).astype(np.int32)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наконец, реализуем сам линейный классификатор!\n",
    "\n",
    "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
    "\n",
    "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
    "\n",
    "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
    "\n",
    "`predictions = X * W`, где `*` - матричное умножение.\n",
    "\n",
    "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement linear_softmax function that uses softmax with cross-entropy for linear classifier\n",
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float64)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float64)\n",
    "target_index = np.ones(batch_size, dtype=np.int32)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И теперь регуляризация\n",
    "\n",
    "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
    "\n",
    "Напомним, L2 regularization определяется как\n",
    "\n",
    "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
    "\n",
    "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиенты в порядке, реализуем процесс тренировки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Implement LinearSoftmaxClassifier.fit function\n",
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=1e-3, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f81e4fbf3a0>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.113\n",
      "Accuracy after training for 100 epochs:  0.116\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
    "plt.plot(loss_history);\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
    "\n",
    "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
    "\n",
    "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
    "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:28<00:56, 28.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.001, reg_strength: 0.0001 => accuracy: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [01:07<00:34, 34.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.001, reg_strength: 1e-05 => accuracy: 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [01:45<00:00, 35.22s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [01:45<03:31, 105.67s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.001, reg_strength: 1e-06 => accuracy: 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 1/3 [00:36<01:12, 36.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.0001, reg_strength: 0.0001 => accuracy: 0.172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [01:06<00:32, 32.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.0001, reg_strength: 1e-05 => accuracy: 0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [01:38<00:00, 32.91s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [03:24<01:41, 101.60s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.0001, reg_strength: 1e-06 => accuracy: 0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 1/3 [00:35<01:11, 35.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 1e-05, reg_strength: 0.0001 => accuracy: 0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [01:07<00:33, 33.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 1e-05, reg_strength: 1e-05 => accuracy: 0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [01:47<00:00, 35.86s/it]\u001b[A\n",
      "100%|██████████| 3/3 [05:12<00:00, 104.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 1e-05, reg_strength: 1e-06 => accuracy: 0.098\n",
      "best validation accuracy achieved: 0.227000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 300\n",
    "\n",
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "reg_strengths = [1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for learning_rate in tqdm(learning_rates):\n",
    "    for reg_strength in tqdm(reg_strengths):\n",
    "        classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "        classifier.fit(train_X, train_y, \n",
    "                       epochs=num_epochs, learning_rate=learning_rate,\n",
    "                       batch_size=batch_size, reg=reg_strength)\n",
    "\n",
    "        pred = classifier.predict(val_X)        \n",
    "        accuracy = multiclass_accuracy(pred, val_y)\n",
    "        if best_val_accuracy is None or accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = accuracy\n",
    "            best_classifier = classifier\n",
    "        print('learning_rate: %s, reg_strength: %s => accuracy: %s' % (learning_rate, reg_strength, accuracy))\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Какой же точности мы добились на тестовых данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear softmax classifier test set accuracy: 0.192000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
