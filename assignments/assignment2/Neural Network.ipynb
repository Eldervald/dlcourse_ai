{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float64) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float64) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1, -2, 3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for 0_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 0_B\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for 0_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 0_B\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03342b63d0>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.284906, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242692, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279424, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315797, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291533, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242361, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259548, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.306860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263498, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320113, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.310367, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314918, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289817, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256856, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247359, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.369704, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179992, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.359666, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236646, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251566, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.327203, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.312869, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280946, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.312399, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297599, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293954, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300021, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.323295, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317361, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274973, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304328, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254193, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311597, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282063, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277536, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273149, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259854, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.333531, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243650, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.335830, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.320055, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.313986, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.294069, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.284094, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.277865, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.214129, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.237839, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.316008, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.167856, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.731875, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.114886, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.982821, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.123514, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.708389, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.374617, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.575493, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.851444, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.066460, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.598900, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.333053, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.804008, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.816695, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.277450, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.928175, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.667880, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.420126, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.404702, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.450082, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.706158, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.913306, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 1.405494, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.956782, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.354699, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.750478, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.666822, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.324699, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.448076, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.620860, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.615819, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 2.037262, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.780885, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.552399, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.499252, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.925927, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.690709, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.439548, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.200840, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.120434, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.799219, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.819070, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.596394, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.274243, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.727602, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.423375, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.857000, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.372114, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 2.132652, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.126755, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.046239, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.344809, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.600889, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.385271, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.687498, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.056517, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.168146, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.953813, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.035292, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.017961, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.912246, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.218221, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.284205, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.093385, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.256134, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.420246, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.346262, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.423637, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 0.965198, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.248756, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.327375, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.647581, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.656482, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.162388, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.557914, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.536330, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.342079, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.704549, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.275606, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.999604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.049859, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.945996, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.222846, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.668301, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.309421, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.313249, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.429223, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.878146, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.643033, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.520639, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.109628, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.708835, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.322088, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.357729, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.534886, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.326171, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.236459, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.433890, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.735226, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.553873, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.405389, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.340745, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.219969, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.192039, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.333067, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.422823, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.441931, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.320401, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.484318, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229580, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.290343, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.243568, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.336177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.117419, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.274132, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.249899, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.211722, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.481234, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.230791, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.192249, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.418718, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.188546, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.580501, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.298824, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.334062, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.151346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.603832, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.262320, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.159190, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.328048, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.267489, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.186284, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.423161, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.482741, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.525613, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.377793, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.440700, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.150671, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.217820, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.294053, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.150083, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.315950, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.260734, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.115864, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1.908583, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.919218, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.781843, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.240342, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Loss: 2.030809, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 0.724831, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.467886, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 0.867009, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.029513, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.046875, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.047815, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.022468, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.008150, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.002424, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.007047, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.001174, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.001042, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 0)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current parameters are (64, 20, 128, 0.99, 0.8, 0.01, 0.1)\n",
      "val_accuracy = 0.456\n",
      "Current parameters are (64, 20, 128, 0.99, 0.8, 0.01, 0.01)\n",
      "val_accuracy = 0.608\n",
      "Current parameters are (64, 20, 128, 0.99, 0.8, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.99, 0.8, 0.005, 0.1)\n",
      "val_accuracy = 0.546\n",
      "Current parameters are (64, 20, 128, 0.99, 0.8, 0.005, 0.01)\n",
      "val_accuracy = 0.673\n",
      "Current parameters are (64, 20, 128, 0.99, 0.8, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.99, 0.8, 0.001, 0.1)\n",
      "val_accuracy = 0.624\n",
      "Current parameters are (64, 20, 128, 0.99, 0.8, 0.001, 0.01)\n",
      "val_accuracy = 0.7\n",
      "Current parameters are (64, 20, 128, 0.99, 0.8, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.99, 0.9, 0.01, 0.1)\n",
      "val_accuracy = 0.407\n",
      "Current parameters are (64, 20, 128, 0.99, 0.9, 0.01, 0.01)\n",
      "val_accuracy = 0.616\n",
      "Current parameters are (64, 20, 128, 0.99, 0.9, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.99, 0.9, 0.005, 0.1)\n",
      "val_accuracy = 0.587\n",
      "Current parameters are (64, 20, 128, 0.99, 0.9, 0.005, 0.01)\n",
      "val_accuracy = 0.677\n",
      "Current parameters are (64, 20, 128, 0.99, 0.9, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.99, 0.9, 0.001, 0.1)\n",
      "val_accuracy = 0.656\n",
      "Current parameters are (64, 20, 128, 0.99, 0.9, 0.001, 0.01)\n",
      "val_accuracy = 0.699\n",
      "Current parameters are (64, 20, 128, 0.99, 0.9, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.99, 0.85, 0.01, 0.1)\n",
      "val_accuracy = 0.445\n",
      "Current parameters are (64, 20, 128, 0.99, 0.85, 0.01, 0.01)\n",
      "val_accuracy = 0.611\n",
      "Current parameters are (64, 20, 128, 0.99, 0.85, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.99, 0.85, 0.005, 0.1)\n",
      "val_accuracy = 0.51\n",
      "Current parameters are (64, 20, 128, 0.99, 0.85, 0.005, 0.01)\n",
      "val_accuracy = 0.677\n",
      "Current parameters are (64, 20, 128, 0.99, 0.85, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.99, 0.85, 0.001, 0.1)\n",
      "val_accuracy = 0.642\n",
      "Current parameters are (64, 20, 128, 0.99, 0.85, 0.001, 0.01)\n",
      "val_accuracy = 0.71\n",
      "Current parameters are (64, 20, 128, 0.99, 0.85, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.9, 0.8, 0.01, 0.1)\n",
      "val_accuracy = 0.645\n",
      "Current parameters are (64, 20, 128, 0.9, 0.8, 0.01, 0.01)\n",
      "val_accuracy = 0.465\n",
      "Current parameters are (64, 20, 128, 0.9, 0.8, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.9, 0.8, 0.005, 0.1)\n",
      "val_accuracy = 0.732\n",
      "Current parameters are (64, 20, 128, 0.9, 0.8, 0.005, 0.01)\n",
      "val_accuracy = 0.533\n",
      "Current parameters are (64, 20, 128, 0.9, 0.8, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.9, 0.8, 0.001, 0.1)\n",
      "val_accuracy = 0.766\n",
      "Current parameters are (64, 20, 128, 0.9, 0.8, 0.001, 0.01)\n",
      "val_accuracy = 0.59\n",
      "Current parameters are (64, 20, 128, 0.9, 0.8, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.9, 0.9, 0.01, 0.1)\n",
      "val_accuracy = 0.645\n",
      "Current parameters are (64, 20, 128, 0.9, 0.9, 0.01, 0.01)\n",
      "val_accuracy = 0.441\n",
      "Current parameters are (64, 20, 128, 0.9, 0.9, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.9, 0.9, 0.005, 0.1)\n",
      "val_accuracy = 0.714\n",
      "Current parameters are (64, 20, 128, 0.9, 0.9, 0.005, 0.01)\n",
      "val_accuracy = 0.529\n",
      "Current parameters are (64, 20, 128, 0.9, 0.9, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.9, 0.9, 0.001, 0.1)\n",
      "val_accuracy = 0.775\n",
      "Current parameters are (64, 20, 128, 0.9, 0.9, 0.001, 0.01)\n",
      "val_accuracy = 0.576\n",
      "Current parameters are (64, 20, 128, 0.9, 0.9, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.9, 0.85, 0.01, 0.1)\n",
      "val_accuracy = 0.628\n",
      "Current parameters are (64, 20, 128, 0.9, 0.85, 0.01, 0.01)\n",
      "val_accuracy = 0.424\n",
      "Current parameters are (64, 20, 128, 0.9, 0.85, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.9, 0.85, 0.005, 0.1)\n",
      "val_accuracy = 0.687\n",
      "Current parameters are (64, 20, 128, 0.9, 0.85, 0.005, 0.01)\n",
      "val_accuracy = 0.52\n",
      "Current parameters are (64, 20, 128, 0.9, 0.85, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.9, 0.85, 0.001, 0.1)\n",
      "val_accuracy = 0.755\n",
      "Current parameters are (64, 20, 128, 0.9, 0.85, 0.001, 0.01)\n",
      "val_accuracy = 0.586\n",
      "Current parameters are (64, 20, 128, 0.9, 0.85, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.85, 0.8, 0.01, 0.1)\n",
      "val_accuracy = 0.659\n",
      "Current parameters are (64, 20, 128, 0.85, 0.8, 0.01, 0.01)\n",
      "val_accuracy = 0.361\n",
      "Current parameters are (64, 20, 128, 0.85, 0.8, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.85, 0.8, 0.005, 0.1)\n",
      "val_accuracy = 0.714\n",
      "Current parameters are (64, 20, 128, 0.85, 0.8, 0.005, 0.01)\n",
      "val_accuracy = 0.38\n",
      "Current parameters are (64, 20, 128, 0.85, 0.8, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.85, 0.8, 0.001, 0.1)\n",
      "val_accuracy = 0.764\n",
      "Current parameters are (64, 20, 128, 0.85, 0.8, 0.001, 0.01)\n",
      "val_accuracy = 0.44\n",
      "Current parameters are (64, 20, 128, 0.85, 0.8, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.85, 0.9, 0.01, 0.1)\n",
      "val_accuracy = 0.675\n",
      "Current parameters are (64, 20, 128, 0.85, 0.9, 0.01, 0.01)\n",
      "val_accuracy = 0.348\n",
      "Current parameters are (64, 20, 128, 0.85, 0.9, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.85, 0.9, 0.005, 0.1)\n",
      "val_accuracy = 0.726\n",
      "Current parameters are (64, 20, 128, 0.85, 0.9, 0.005, 0.01)\n",
      "val_accuracy = 0.385\n",
      "Current parameters are (64, 20, 128, 0.85, 0.9, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.85, 0.9, 0.001, 0.1)\n",
      "val_accuracy = 0.767\n",
      "Current parameters are (64, 20, 128, 0.85, 0.9, 0.001, 0.01)\n",
      "val_accuracy = 0.446\n",
      "Current parameters are (64, 20, 128, 0.85, 0.9, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.85, 0.85, 0.01, 0.1)\n",
      "val_accuracy = 0.667\n",
      "Current parameters are (64, 20, 128, 0.85, 0.85, 0.01, 0.01)\n",
      "val_accuracy = 0.332\n",
      "Current parameters are (64, 20, 128, 0.85, 0.85, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.85, 0.85, 0.005, 0.1)\n",
      "val_accuracy = 0.722\n",
      "Current parameters are (64, 20, 128, 0.85, 0.85, 0.005, 0.01)\n",
      "val_accuracy = 0.392\n",
      "Current parameters are (64, 20, 128, 0.85, 0.85, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 128, 0.85, 0.85, 0.001, 0.1)\n",
      "val_accuracy = 0.763\n",
      "Current parameters are (64, 20, 128, 0.85, 0.85, 0.001, 0.01)\n",
      "val_accuracy = 0.461\n",
      "Current parameters are (64, 20, 128, 0.85, 0.85, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Best parameters for now are (0.775, 64, 20, 128, 0.9, 0.9, 0.001, 0.1)\n",
      "Current parameters are (64, 20, 256, 0.99, 0.8, 0.01, 0.1)\n",
      "val_accuracy = 0.399\n",
      "Current parameters are (64, 20, 256, 0.99, 0.8, 0.01, 0.01)\n",
      "val_accuracy = 0.615\n",
      "Current parameters are (64, 20, 256, 0.99, 0.8, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.99, 0.8, 0.005, 0.1)\n",
      "val_accuracy = 0.503\n",
      "Current parameters are (64, 20, 256, 0.99, 0.8, 0.005, 0.01)\n",
      "val_accuracy = 0.684\n",
      "Current parameters are (64, 20, 256, 0.99, 0.8, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.99, 0.8, 0.001, 0.1)\n",
      "val_accuracy = 0.629\n",
      "Current parameters are (64, 20, 256, 0.99, 0.8, 0.001, 0.01)\n",
      "val_accuracy = 0.721\n",
      "Current parameters are (64, 20, 256, 0.99, 0.8, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.99, 0.9, 0.01, 0.1)\n",
      "val_accuracy = 0.444\n",
      "Current parameters are (64, 20, 256, 0.99, 0.9, 0.01, 0.01)\n",
      "val_accuracy = 0.611\n",
      "Current parameters are (64, 20, 256, 0.99, 0.9, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.99, 0.9, 0.005, 0.1)\n",
      "val_accuracy = 0.544\n",
      "Current parameters are (64, 20, 256, 0.99, 0.9, 0.005, 0.01)\n",
      "val_accuracy = 0.694\n",
      "Current parameters are (64, 20, 256, 0.99, 0.9, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.99, 0.9, 0.001, 0.1)\n",
      "val_accuracy = 0.665\n",
      "Current parameters are (64, 20, 256, 0.99, 0.9, 0.001, 0.01)\n",
      "val_accuracy = 0.717\n",
      "Current parameters are (64, 20, 256, 0.99, 0.9, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.99, 0.85, 0.01, 0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_accuracy = 0.489\n",
      "Current parameters are (64, 20, 256, 0.99, 0.85, 0.01, 0.01)\n",
      "val_accuracy = 0.626\n",
      "Current parameters are (64, 20, 256, 0.99, 0.85, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.99, 0.85, 0.005, 0.1)\n",
      "val_accuracy = 0.539\n",
      "Current parameters are (64, 20, 256, 0.99, 0.85, 0.005, 0.01)\n",
      "val_accuracy = 0.685\n",
      "Current parameters are (64, 20, 256, 0.99, 0.85, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.99, 0.85, 0.001, 0.1)\n",
      "val_accuracy = 0.649\n",
      "Current parameters are (64, 20, 256, 0.99, 0.85, 0.001, 0.01)\n",
      "val_accuracy = 0.713\n",
      "Current parameters are (64, 20, 256, 0.99, 0.85, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.9, 0.8, 0.01, 0.1)\n",
      "val_accuracy = 0.64\n",
      "Current parameters are (64, 20, 256, 0.9, 0.8, 0.01, 0.01)\n",
      "val_accuracy = 0.483\n",
      "Current parameters are (64, 20, 256, 0.9, 0.8, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.9, 0.8, 0.005, 0.1)\n",
      "val_accuracy = 0.696\n",
      "Current parameters are (64, 20, 256, 0.9, 0.8, 0.005, 0.01)\n",
      "val_accuracy = 0.556\n",
      "Current parameters are (64, 20, 256, 0.9, 0.8, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.9, 0.8, 0.001, 0.1)\n",
      "val_accuracy = 0.776\n",
      "Current parameters are (64, 20, 256, 0.9, 0.8, 0.001, 0.01)\n",
      "val_accuracy = 0.597\n",
      "Current parameters are (64, 20, 256, 0.9, 0.8, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.9, 0.9, 0.01, 0.1)\n",
      "val_accuracy = 0.656\n",
      "Current parameters are (64, 20, 256, 0.9, 0.9, 0.01, 0.01)\n",
      "val_accuracy = 0.459\n",
      "Current parameters are (64, 20, 256, 0.9, 0.9, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.9, 0.9, 0.005, 0.1)\n",
      "val_accuracy = 0.718\n",
      "Current parameters are (64, 20, 256, 0.9, 0.9, 0.005, 0.01)\n",
      "val_accuracy = 0.548\n",
      "Current parameters are (64, 20, 256, 0.9, 0.9, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.9, 0.9, 0.001, 0.1)\n",
      "val_accuracy = 0.772\n",
      "Current parameters are (64, 20, 256, 0.9, 0.9, 0.001, 0.01)\n",
      "val_accuracy = 0.603\n",
      "Current parameters are (64, 20, 256, 0.9, 0.9, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.9, 0.85, 0.01, 0.1)\n",
      "val_accuracy = 0.653\n",
      "Current parameters are (64, 20, 256, 0.9, 0.85, 0.01, 0.01)\n",
      "val_accuracy = 0.475\n",
      "Current parameters are (64, 20, 256, 0.9, 0.85, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.9, 0.85, 0.005, 0.1)\n",
      "val_accuracy = 0.684\n",
      "Current parameters are (64, 20, 256, 0.9, 0.85, 0.005, 0.01)\n",
      "val_accuracy = 0.553\n",
      "Current parameters are (64, 20, 256, 0.9, 0.85, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.9, 0.85, 0.001, 0.1)\n",
      "val_accuracy = 0.776\n",
      "Current parameters are (64, 20, 256, 0.9, 0.85, 0.001, 0.01)\n",
      "val_accuracy = 0.606\n",
      "Current parameters are (64, 20, 256, 0.9, 0.85, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.85, 0.8, 0.01, 0.1)\n",
      "val_accuracy = 0.651\n",
      "Current parameters are (64, 20, 256, 0.85, 0.8, 0.01, 0.01)\n",
      "val_accuracy = 0.375\n",
      "Current parameters are (64, 20, 256, 0.85, 0.8, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.85, 0.8, 0.005, 0.1)\n",
      "val_accuracy = 0.727\n",
      "Current parameters are (64, 20, 256, 0.85, 0.8, 0.005, 0.01)\n",
      "val_accuracy = 0.419\n",
      "Current parameters are (64, 20, 256, 0.85, 0.8, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.85, 0.8, 0.001, 0.1)\n",
      "val_accuracy = 0.776\n",
      "Current parameters are (64, 20, 256, 0.85, 0.8, 0.001, 0.01)\n",
      "val_accuracy = 0.487\n",
      "Current parameters are (64, 20, 256, 0.85, 0.8, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.85, 0.9, 0.01, 0.1)\n",
      "val_accuracy = 0.665\n",
      "Current parameters are (64, 20, 256, 0.85, 0.9, 0.01, 0.01)\n",
      "val_accuracy = 0.359\n",
      "Current parameters are (64, 20, 256, 0.85, 0.9, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.85, 0.9, 0.005, 0.1)\n",
      "val_accuracy = 0.735\n",
      "Current parameters are (64, 20, 256, 0.85, 0.9, 0.005, 0.01)\n",
      "val_accuracy = 0.424\n",
      "Current parameters are (64, 20, 256, 0.85, 0.9, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.85, 0.9, 0.001, 0.1)\n",
      "val_accuracy = 0.775\n",
      "Current parameters are (64, 20, 256, 0.85, 0.9, 0.001, 0.01)\n",
      "val_accuracy = 0.49\n",
      "Current parameters are (64, 20, 256, 0.85, 0.9, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.85, 0.85, 0.01, 0.1)\n",
      "val_accuracy = 0.663\n",
      "Current parameters are (64, 20, 256, 0.85, 0.85, 0.01, 0.01)\n",
      "val_accuracy = 0.377\n",
      "Current parameters are (64, 20, 256, 0.85, 0.85, 0.01, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.85, 0.85, 0.005, 0.1)\n",
      "val_accuracy = 0.72\n",
      "Current parameters are (64, 20, 256, 0.85, 0.85, 0.005, 0.01)\n",
      "val_accuracy = 0.424\n",
      "Current parameters are (64, 20, 256, 0.85, 0.85, 0.005, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Current parameters are (64, 20, 256, 0.85, 0.85, 0.001, 0.1)\n",
      "val_accuracy = 0.765\n",
      "Current parameters are (64, 20, 256, 0.85, 0.85, 0.001, 0.01)\n",
      "val_accuracy = 0.498\n",
      "Current parameters are (64, 20, 256, 0.85, 0.85, 0.001, 0.001)\n",
      "val_accuracy = 0.206\n",
      "Best parameters for now are (0.776, 64, 20, 256, 0.9, 0.8, 0.001, 0.1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-36765dc5ac49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best parameters for now are {best_parameters}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best validation accuracy achieved: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbest_val_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [1e-1, 1e-2, 1e-3]\n",
    "reg_strength = [1e-2, 5e-3, 1e-3] \n",
    "learning_rate_decay = [0.99, 0.9, 0.85]\n",
    "hidden_layer_size = [128, 256]\n",
    "momentum = [0.8, 0.9, 0.85]\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_parameters = (-1, 0, 0, 0, 0, 0 ,0)\n",
    "for laysize in hidden_layer_size:\n",
    "    for decay in learning_rate_decay:\n",
    "        for moment in momentum:\n",
    "            for reg in reg_strength:\n",
    "                for rate in learning_rates:\n",
    "                    print(f'Current parameters are {(batch_size, num_epochs, laysize, decay, moment, reg, rate)}')\n",
    "                    model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = laysize, reg = reg)\n",
    "                    dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "                    trainer = Trainer(model, dataset, MomentumSGD(moment), \n",
    "                                      learning_rate=rate, num_epochs=num_epochs, \n",
    "                                      batch_size=batch_size, learning_rate_decay=decay)\n",
    "                    \n",
    "                    loss_history, train_history, val_history = trainer.fit()\n",
    "                    print(f'val_accuracy = {val_history[len(val_history)-1]}')\n",
    "                    if best_parameters[0] < val_history[len(val_history)-1]:\n",
    "                        best_parameters = (val_history[len(val_history)-1], batch_size, num_epochs, laysize, decay, moment, reg, rate)\n",
    "    print(f'Best parameters for now are {best_parameters}')\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_parameters: (0.776, 64, 20, 256, 0.9, 0.8, 0.001, 0.1)\n",
      "best validation accuracy achieved: 0.774000\n"
     ]
    }
   ],
   "source": [
    "print(f\"best_parameters: {best_parameters}\")\n",
    "best_classifier = TwoLayerNet(n_input = train_X.shape[1],n_output = 10, hidden_layer_size = best_parameters[3], reg = best_parameters[6])\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "best_classifier_trainer = Trainer(best_classifier, dataset, MomentumSGD(best_parameters[5]), learning_rate=best_parameters[7], num_epochs=best_parameters[2], batch_size=best_parameters[1], learning_rate_decay = best_parameters[4])\n",
    "loss_history, train_history, val_history = best_classifier_trainer.fit()\n",
    "\n",
    "print('best validation accuracy achieved: %f' % max(val_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train is red\n",
      "Validation is blue\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history, color='red')\n",
    "plt.plot(val_history, color='blue')\n",
    "\n",
    "print('Train is red')\n",
    "print('Validation is blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.742000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
