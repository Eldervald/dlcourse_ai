{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2BcsGGynHje"
      },
      "source": [
        "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
        "\n",
        "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P59NYU98GCb9"
      },
      "source": [
        "!pip3 -qq install bokeh\n",
        "!pip3 -qq install gensim\n",
        "!pip3 -qq install nltk\n",
        "!pip3 -qq install scikit-learn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sVtGHmA9aBM"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiA2dGmgF1rW",
        "outputId": "9569cea9-4a81-4615-a7f7-5b22cc5c3c80"
      },
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QstS4NO0L97c",
        "outputId": "a5707a1a-97e7-4368-d6ce-cbbadb4a5d08"
      },
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTai8Ta0lgwL",
        "outputId": "65b89477-0c7a-4cb3-f134-714f1ecb0f85"
      },
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCjwwDs6Zq9x",
        "outputId": "762066f1-eb10-433b-e0c8-83edc9c2397e"
      },
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words in train = 45441. Tags = {'VERB', 'NOUN', 'ADV', 'ADJ', 'PRT', 'DET', '.', 'PRON', 'X', 'NUM', 'ADP', 'CONJ'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "URC1B2nvPGFt",
        "outputId": "60b8fb2c-f3ff-4060-837d-678467a1d75a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rWmSToIaeAo",
        "outputId": "00b0e669-b9d8-45c0-8c02-30357c5748fd"
      },
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Ymb_MkbWsF"
      },
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjz_Rk0bbMyH",
        "outputId": "9e0bd505-36f4-4880-ff09-185fae9afd93"
      },
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of bigram tagger = 93.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWMw6QHvbaDd"
      },
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XCuxEBVbOY_",
        "outputId": "db1ccdfe-6eb2-4099-c77b-654f560f244e"
      },
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of trigram tagger = 23.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtRbz1SwgEqc"
      },
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhsTKZalfih6"
      },
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4XsRII5kW5x",
        "outputId": "0ca794ef-5c83-4503-a64e-2f5e8c570fc0"
      },
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 4), (32, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5I9E9P6eFYv"
      },
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVEHju54d68T"
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(input_size=word_emb_dim, hidden_size=lstm_hidden_dim, num_layers=lstm_layers_count)\n",
        "        self.regression = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embedding_out = self.embedding(inputs)\n",
        "        lstm_out, _ = self.lstm.forward(embedding_out)\n",
        "        out = self.regression.forward(lstm_out)\n",
        "        return out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbrxsZ2mehWB",
        "outputId": "bd0ddeb0-6737-4098-b150-48d4c414d3d3"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "\n",
        "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
        "\n",
        "logits = model(X_batch)\n",
        "\n",
        "def compute_correct(logits, y_batch):\n",
        "    indices = torch.max(logits, dim=2)[1]\n",
        "\n",
        "    correct_samples = float(torch.sum(indices[y_batch != 0] == y_batch[y_batch != 0]))\n",
        "\n",
        "    return correct_samples, y_batch[y_batch != 0].shape[0]\n",
        "\n",
        "print(compute_correct(logits, y_batch))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6.0, 92)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoT8KrZ8Ib6I",
        "outputId": "d011caf6-7409-4c56-845f-5e1c1d6a87ef"
      },
      "source": [
        "logits.view(-1, 13).shape, y_batch.view(-1).shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 13]), torch.Size([128]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMUyUm1hgpe3",
        "outputId": "b6e73fe0-7268-4499-eb02-ac74f2a23d11"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "criterion(logits.view(-1, 13), y_batch.view(-1))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5560, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSgV3NPUpcjH"
      },
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FprPQ0gllo7b"
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "                logits = model(X_batch)\n",
        "\n",
        "                loss = criterion(logits.view(-1, 13), y_batch.view(-1))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                cur_correct_count, cur_sum_count = compute_correct(logits, y_batch)\n",
        "\n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count, correct_count / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None):\n",
        "        \n",
        "    if not val_data is None and val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_data is None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqfbeh1ltEYa",
        "outputId": "cd92acfc-9750-46d9-c07c-8b0d83057b36"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 20] Train: Loss = 0.32107, Accuracy = 71.01%: 100%|██████████| 572/572 [00:12<00:00, 44.55it/s]\n",
            "[1 / 20]   Val: Loss = 0.10125, Accuracy = 84.67%: 100%|██████████| 13/13 [00:00<00:00, 34.82it/s]\n",
            "[2 / 20] Train: Loss = 0.10124, Accuracy = 89.90%: 100%|██████████| 572/572 [00:12<00:00, 46.87it/s]\n",
            "[2 / 20]   Val: Loss = 0.07342, Accuracy = 89.79%: 100%|██████████| 13/13 [00:00<00:00, 36.09it/s]\n",
            "[3 / 20] Train: Loss = 0.06779, Accuracy = 93.25%: 100%|██████████| 572/572 [00:11<00:00, 47.75it/s]\n",
            "[3 / 20]   Val: Loss = 0.06244, Accuracy = 91.46%: 100%|██████████| 13/13 [00:00<00:00, 36.53it/s]\n",
            "[4 / 20] Train: Loss = 0.05133, Accuracy = 94.84%: 100%|██████████| 572/572 [00:11<00:00, 47.73it/s]\n",
            "[4 / 20]   Val: Loss = 0.06272, Accuracy = 92.20%: 100%|██████████| 13/13 [00:00<00:00, 35.86it/s]\n",
            "[5 / 20] Train: Loss = 0.04091, Accuracy = 95.84%: 100%|██████████| 572/572 [00:12<00:00, 47.04it/s]\n",
            "[5 / 20]   Val: Loss = 0.05517, Accuracy = 92.73%: 100%|██████████| 13/13 [00:00<00:00, 33.38it/s]\n",
            "[6 / 20] Train: Loss = 0.03305, Accuracy = 96.61%: 100%|██████████| 572/572 [00:12<00:00, 47.43it/s]\n",
            "[6 / 20]   Val: Loss = 0.05894, Accuracy = 93.09%: 100%|██████████| 13/13 [00:00<00:00, 37.23it/s]\n",
            "[7 / 20] Train: Loss = 0.02759, Accuracy = 97.15%: 100%|██████████| 572/572 [00:11<00:00, 48.20it/s]\n",
            "[7 / 20]   Val: Loss = 0.06025, Accuracy = 93.26%: 100%|██████████| 13/13 [00:00<00:00, 37.53it/s]\n",
            "[8 / 20] Train: Loss = 0.02261, Accuracy = 97.63%: 100%|██████████| 572/572 [00:11<00:00, 48.50it/s]\n",
            "[8 / 20]   Val: Loss = 0.06482, Accuracy = 93.40%: 100%|██████████| 13/13 [00:00<00:00, 36.76it/s]\n",
            "[9 / 20] Train: Loss = 0.01908, Accuracy = 98.01%: 100%|██████████| 572/572 [00:11<00:00, 48.96it/s]\n",
            "[9 / 20]   Val: Loss = 0.06063, Accuracy = 93.47%: 100%|██████████| 13/13 [00:00<00:00, 35.10it/s]\n",
            "[10 / 20] Train: Loss = 0.01605, Accuracy = 98.34%: 100%|██████████| 572/572 [00:11<00:00, 48.74it/s]\n",
            "[10 / 20]   Val: Loss = 0.06762, Accuracy = 93.45%: 100%|██████████| 13/13 [00:00<00:00, 37.64it/s]\n",
            "[11 / 20] Train: Loss = 0.01329, Accuracy = 98.62%: 100%|██████████| 572/572 [00:11<00:00, 48.22it/s]\n",
            "[11 / 20]   Val: Loss = 0.07027, Accuracy = 93.41%: 100%|██████████| 13/13 [00:00<00:00, 36.04it/s]\n",
            "[12 / 20] Train: Loss = 0.01095, Accuracy = 98.89%: 100%|██████████| 572/572 [00:11<00:00, 48.50it/s]\n",
            "[12 / 20]   Val: Loss = 0.07778, Accuracy = 93.40%: 100%|██████████| 13/13 [00:00<00:00, 35.10it/s]\n",
            "[13 / 20] Train: Loss = 0.00890, Accuracy = 99.10%: 100%|██████████| 572/572 [00:11<00:00, 48.33it/s]\n",
            "[13 / 20]   Val: Loss = 0.07524, Accuracy = 93.29%: 100%|██████████| 13/13 [00:00<00:00, 36.93it/s]\n",
            "[14 / 20] Train: Loss = 0.00727, Accuracy = 99.29%: 100%|██████████| 572/572 [00:11<00:00, 49.59it/s]\n",
            "[14 / 20]   Val: Loss = 0.07917, Accuracy = 93.27%: 100%|██████████| 13/13 [00:00<00:00, 37.11it/s]\n",
            "[15 / 20] Train: Loss = 0.00591, Accuracy = 99.43%: 100%|██████████| 572/572 [00:11<00:00, 49.42it/s]\n",
            "[15 / 20]   Val: Loss = 0.08558, Accuracy = 93.19%: 100%|██████████| 13/13 [00:00<00:00, 37.96it/s]\n",
            "[16 / 20] Train: Loss = 0.00481, Accuracy = 99.56%: 100%|██████████| 572/572 [00:11<00:00, 49.58it/s]\n",
            "[16 / 20]   Val: Loss = 0.08471, Accuracy = 93.19%: 100%|██████████| 13/13 [00:00<00:00, 37.62it/s]\n",
            "[17 / 20] Train: Loss = 0.00406, Accuracy = 99.63%: 100%|██████████| 572/572 [00:11<00:00, 48.94it/s]\n",
            "[17 / 20]   Val: Loss = 0.09636, Accuracy = 93.19%: 100%|██████████| 13/13 [00:00<00:00, 38.77it/s]\n",
            "[18 / 20] Train: Loss = 0.00339, Accuracy = 99.69%: 100%|██████████| 572/572 [00:11<00:00, 49.11it/s]\n",
            "[18 / 20]   Val: Loss = 0.09688, Accuracy = 93.16%: 100%|██████████| 13/13 [00:00<00:00, 36.86it/s]\n",
            "[19 / 20] Train: Loss = 0.00279, Accuracy = 99.75%: 100%|██████████| 572/572 [00:11<00:00, 49.02it/s]\n",
            "[19 / 20]   Val: Loss = 0.09731, Accuracy = 93.07%: 100%|██████████| 13/13 [00:00<00:00, 36.32it/s]\n",
            "[20 / 20] Train: Loss = 0.00250, Accuracy = 99.78%: 100%|██████████| 572/572 [00:11<00:00, 48.92it/s]\n",
            "[20 / 20]   Val: Loss = 0.11033, Accuracy = 93.10%: 100%|██████████| 13/13 [00:00<00:00, 38.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0qGetIhfUE5"
      },
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAfV2dEOfHo5"
      },
      "source": [
        "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98wr38_rw55D",
        "outputId": "fb980aba-b07e-45b5-906c-b8a151678ffb"
      },
      "source": [
        "val_loss, val_acc = do_epoch(model, criterion, (X_test, y_test), len(X_test), None, 'Test:')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: Loss = 0.05739, Accuracy = 93.19%: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZBNmdHRnHk7"
      },
      "source": [
        "class BiLSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(input_size=word_emb_dim, hidden_size=lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
        "        self.regression = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embedding_out = self.embedding(inputs)\n",
        "        lstm_out, *_ = self.lstm.forward(embedding_out)\n",
        "        out = self.regression.forward(lstm_out)\n",
        "        return out"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTXmYGD_ANhm"
      },
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZpY_Q1xZ18h",
        "outputId": "6361003a-5baf-4115-c748-60bdffa758b0"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsCstxiO03oT",
        "outputId": "7b27edac-bdb9-4aed-93a7-069c3bba8f9c"
      },
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Know 38736 out of 45441 word embeddings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxaRBpQd0pat"
      },
      "source": [
        "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings=FloatTensor(embeddings))\n",
        "        self.lstm = nn.LSTM(input_size=embeddings.shape[1], hidden_size=lstm_hidden_dim, num_layers=lstm_layers_count, bidirectional=True)\n",
        "        self.regression = nn.Linear(lstm_hidden_dim * 2, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embedding_out = self.embedding(inputs)\n",
        "        lstm_out, *_ = self.lstm.forward(embedding_out)\n",
        "        out = self.regression.forward(lstm_out)\n",
        "        return out"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBtI6BDE-Fc7",
        "outputId": "e832e519-1a2d-4457-8fea-25403e322282"
      },
      "source": [
        "model = LSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 20] Train: Loss = 0.55078, Accuracy = 84.24%: 100%|██████████| 572/572 [00:10<00:00, 53.13it/s]\n",
            "[1 / 20]   Val: Loss = 0.25559, Accuracy = 92.43%: 100%|██████████| 13/13 [00:00<00:00, 39.71it/s]\n",
            "[2 / 20] Train: Loss = 0.18702, Accuracy = 94.48%: 100%|██████████| 572/572 [00:10<00:00, 55.20it/s]\n",
            "[2 / 20]   Val: Loss = 0.17723, Accuracy = 94.69%: 100%|██████████| 13/13 [00:00<00:00, 39.86it/s]\n",
            "[3 / 20] Train: Loss = 0.13315, Accuracy = 96.04%: 100%|██████████| 572/572 [00:10<00:00, 55.79it/s]\n",
            "[3 / 20]   Val: Loss = 0.13981, Accuracy = 95.73%: 100%|██████████| 13/13 [00:00<00:00, 39.93it/s]\n",
            "[4 / 20] Train: Loss = 0.10764, Accuracy = 96.75%: 100%|██████████| 572/572 [00:10<00:00, 55.65it/s]\n",
            "[4 / 20]   Val: Loss = 0.12333, Accuracy = 96.17%: 100%|██████████| 13/13 [00:00<00:00, 38.27it/s]\n",
            "[5 / 20] Train: Loss = 0.09259, Accuracy = 97.20%: 100%|██████████| 572/572 [00:10<00:00, 57.19it/s]\n",
            "[5 / 20]   Val: Loss = 0.11569, Accuracy = 96.40%: 100%|██████████| 13/13 [00:00<00:00, 41.23it/s]\n",
            "[6 / 20] Train: Loss = 0.08246, Accuracy = 97.49%: 100%|██████████| 572/572 [00:09<00:00, 58.10it/s]\n",
            "[6 / 20]   Val: Loss = 0.10681, Accuracy = 96.64%: 100%|██████████| 13/13 [00:00<00:00, 42.05it/s]\n",
            "[7 / 20] Train: Loss = 0.07487, Accuracy = 97.69%: 100%|██████████| 572/572 [00:10<00:00, 57.09it/s]\n",
            "[7 / 20]   Val: Loss = 0.10226, Accuracy = 96.72%: 100%|██████████| 13/13 [00:00<00:00, 41.64it/s]\n",
            "[8 / 20] Train: Loss = 0.06886, Accuracy = 97.86%: 100%|██████████| 572/572 [00:10<00:00, 56.66it/s]\n",
            "[8 / 20]   Val: Loss = 0.10159, Accuracy = 96.76%: 100%|██████████| 13/13 [00:00<00:00, 41.75it/s]\n",
            "[9 / 20] Train: Loss = 0.06420, Accuracy = 98.00%: 100%|██████████| 572/572 [00:10<00:00, 57.14it/s]\n",
            "[9 / 20]   Val: Loss = 0.09694, Accuracy = 96.88%: 100%|██████████| 13/13 [00:00<00:00, 41.89it/s]\n",
            "[10 / 20] Train: Loss = 0.05987, Accuracy = 98.13%: 100%|██████████| 572/572 [00:09<00:00, 57.44it/s]\n",
            "[10 / 20]   Val: Loss = 0.09473, Accuracy = 96.99%: 100%|██████████| 13/13 [00:00<00:00, 40.28it/s]\n",
            "[11 / 20] Train: Loss = 0.05611, Accuracy = 98.24%: 100%|██████████| 572/572 [00:10<00:00, 56.91it/s]\n",
            "[11 / 20]   Val: Loss = 0.09687, Accuracy = 96.92%: 100%|██████████| 13/13 [00:00<00:00, 40.08it/s]\n",
            "[12 / 20] Train: Loss = 0.05323, Accuracy = 98.32%: 100%|██████████| 572/572 [00:10<00:00, 57.03it/s]\n",
            "[12 / 20]   Val: Loss = 0.09367, Accuracy = 96.99%: 100%|██████████| 13/13 [00:00<00:00, 41.38it/s]\n",
            "[13 / 20] Train: Loss = 0.05049, Accuracy = 98.41%: 100%|██████████| 572/572 [00:10<00:00, 56.70it/s]\n",
            "[13 / 20]   Val: Loss = 0.09260, Accuracy = 97.02%: 100%|██████████| 13/13 [00:00<00:00, 42.44it/s]\n",
            "[14 / 20] Train: Loss = 0.04780, Accuracy = 98.49%: 100%|██████████| 572/572 [00:09<00:00, 57.37it/s]\n",
            "[14 / 20]   Val: Loss = 0.09236, Accuracy = 97.03%: 100%|██████████| 13/13 [00:00<00:00, 39.76it/s]\n",
            "[15 / 20] Train: Loss = 0.04558, Accuracy = 98.56%: 100%|██████████| 572/572 [00:10<00:00, 56.65it/s]\n",
            "[15 / 20]   Val: Loss = 0.09278, Accuracy = 97.04%: 100%|██████████| 13/13 [00:00<00:00, 39.31it/s]\n",
            "[16 / 20] Train: Loss = 0.04337, Accuracy = 98.63%: 100%|██████████| 572/572 [00:10<00:00, 56.95it/s]\n",
            "[16 / 20]   Val: Loss = 0.09408, Accuracy = 97.00%: 100%|██████████| 13/13 [00:00<00:00, 41.91it/s]\n",
            "[17 / 20] Train: Loss = 0.04137, Accuracy = 98.70%: 100%|██████████| 572/572 [00:10<00:00, 56.28it/s]\n",
            "[17 / 20]   Val: Loss = 0.09360, Accuracy = 97.06%: 100%|██████████| 13/13 [00:00<00:00, 41.42it/s]\n",
            "[18 / 20] Train: Loss = 0.03942, Accuracy = 98.75%: 100%|██████████| 572/572 [00:10<00:00, 55.92it/s]\n",
            "[18 / 20]   Val: Loss = 0.09428, Accuracy = 97.05%: 100%|██████████| 13/13 [00:00<00:00, 42.12it/s]\n",
            "[19 / 20] Train: Loss = 0.03773, Accuracy = 98.83%: 100%|██████████| 572/572 [00:10<00:00, 55.90it/s]\n",
            "[19 / 20]   Val: Loss = 0.09933, Accuracy = 96.94%: 100%|██████████| 13/13 [00:00<00:00, 41.61it/s]\n",
            "[20 / 20] Train: Loss = 0.03596, Accuracy = 98.88%: 100%|██████████| 572/572 [00:10<00:00, 55.92it/s]\n",
            "[20 / 20]   Val: Loss = 0.09617, Accuracy = 97.01%: 100%|██████████| 13/13 [00:00<00:00, 40.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ne_8f24h8kg"
      },
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
        "\n",
        "Добейтесь качества лучше прошлых моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPUuAPGhEGVR",
        "outputId": "8748c01e-813f-434c-e5c2-2cde2a35d42f"
      },
      "source": [
        "test_loss, test_acc = do_epoch(model, criterion, (X_test, y_test), len(X_test), None, 'Test:')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test: Loss = 0.09705, Accuracy = 97.06%: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n"
          ]
        }
      ]
    }
  ]
}